[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ankit Borle",
    "section": "",
    "text": "Hi, Welcome to my website.\nMy name is Ankit Borle, I am currently pursuing my Master’s degree in Data Analytics Engineering from George Mason University, Virginia, USA.\nI hold a Bachelors Degree in Mechanical Engineering. i have 3+ years of working experience in IT sector as Production Support Engineer.\nI look forward to work on technologies like Python, R, SQL, and cloud computing platforms, and use big data tools like Hadoop, Spark, and cloud-based platforms like AWS and Google Cloud."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This page is under construction !!!"
  },
  {
    "objectID": "page_1.html",
    "href": "page_1.html",
    "title": "Page 1",
    "section": "",
    "text": "This page is also under construction !!!"
  },
  {
    "objectID": "page_2.html",
    "href": "page_2.html",
    "title": "Page 2",
    "section": "",
    "text": "Even this page is also under construction !!!"
  },
  {
    "objectID": "Pages/MidProject.html",
    "href": "Pages/MidProject.html",
    "title": "Redesigning plot",
    "section": "",
    "text": "Source: A review of the best and worst franchise records in professional sports\nThe visual above presents data on the number of perfect seasons required by teams across various leagues to achieve a .500 winning percentage. Currently, it’s displayed as a simple bar plot, grouped by league. [1]\nTo make it easier to analyze each league individually, especially since the original plot includes numerous teams, we propose redesigning the visualization. By splitting the plot by league and transforming it into a series of line plots, we can gain clearer insights into each league’s performance and trends.\n\n\n\n\n\n\n\n\n\n\n\nAs observed from the league-wise insights, we can analyze not only how teams perform but also identify which teams require the highest and lowest number of perfect seasons to reach a .500 winning percentage. This allows us to determine if teams within a league are generally consistent or if there’s a clear outlier. For example, in the NFL, the Los Angeles Chargers are leading, needing less than a season to reach .500, while the Arizona Cardinals are struggling, requiring 12 seasons to hit the same mark. [3][4]\nNext, we will create a plot that provides deeper insights into each league by displaying key metrics such as the highest and lowest number of seasons required to reach .500, as well as other important data points. This will be visualized using a box plot, offering a clear view of the overall performance distribution within each league. To enhance the analysis, we aim to make the box plot interactive, allowing for a more detailed exploration of the data.\n\n\n\n\n\n\n\n\n\nFrom the box plot above, we can gather a wealth of information, including summary statistics grouped by league. This allows us to easily identify key metrics such as the minimum value, maximum value, first quartile (Q1), third quartile (Q3), and more. These insights help us better understand the distribution of team performances within each league. [3][4]\nA shorter box indicates a more competitive league, where teams are performing at a similar level. In contrast, a longer box suggests one dominant team and weaker competition from others. In the first redesign, the plot for the NFL shows the Los Angeles Chargers dominating, as they need less than a season, while the Arizona Cardinals appear as the weakest team, requiring the most seasons. In contrast, the second redesign for the NFL shows a longer box, indicating a greater disparity between teams. Meanwhile, for the MLS, the box is shorter, reflecting stronger competition and more evenly matched teams. This trend is consistent in the first redesign for MLS, where the number of seasons required by each team is nearly the same.\nThe box plot also helps identify any potential outliers by calculating the upper and lower fences. Values that fall outside these fences are considered outliers. For instance, in the MLS box plot, we observe a value of 1.80 that may be classified as an outlier. However, in this particular case, it might not truly be an outlier. Nonetheless, this feature of box plots is valuable in other scenarios where identifying outliers is crucial..\n\n\n\nIn conclusion, the original visual had a few challenges, making it difficult to identify league-wise performances due to the overcrowding of teams in a single plot, which made trend analysis harder. To address this, we created a line chart grouped by each league, allowing us to easily spot patterns, such as the strongest team and the overall level of competition within the league. We then further refined the design by creating a box plot for each league, providing statistical insights like the distribution of teams, the most common performance range, and the extreme outliers in each league."
  },
  {
    "objectID": "Pages/MidProject.html#original-visual",
    "href": "Pages/MidProject.html#original-visual",
    "title": "Redesigning plot",
    "section": "",
    "text": "Source: A review of the best and worst franchise records in professional sports\nThe visual above presents data on the number of perfect seasons required by teams across various leagues to achieve a .500 winning percentage. Currently, it’s displayed as a simple bar plot, grouped by league. [1]\nTo make it easier to analyze each league individually, especially since the original plot includes numerous teams, we propose redesigning the visualization. By splitting the plot by league and transforming it into a series of line plots, we can gain clearer insights into each league’s performance and trends.\n\n\n\n\n\n\n\n\n\n\n\nAs observed from the league-wise insights, we can analyze not only how teams perform but also identify which teams require the highest and lowest number of perfect seasons to reach a .500 winning percentage. This allows us to determine if teams within a league are generally consistent or if there’s a clear outlier. For example, in the NFL, the Los Angeles Chargers are leading, needing less than a season to reach .500, while the Arizona Cardinals are struggling, requiring 12 seasons to hit the same mark. [3][4]\nNext, we will create a plot that provides deeper insights into each league by displaying key metrics such as the highest and lowest number of seasons required to reach .500, as well as other important data points. This will be visualized using a box plot, offering a clear view of the overall performance distribution within each league. To enhance the analysis, we aim to make the box plot interactive, allowing for a more detailed exploration of the data.\n\n\n\n\n\n\n\n\n\nFrom the box plot above, we can gather a wealth of information, including summary statistics grouped by league. This allows us to easily identify key metrics such as the minimum value, maximum value, first quartile (Q1), third quartile (Q3), and more. These insights help us better understand the distribution of team performances within each league. [3][4]\nA shorter box indicates a more competitive league, where teams are performing at a similar level. In contrast, a longer box suggests one dominant team and weaker competition from others. In the first redesign, the plot for the NFL shows the Los Angeles Chargers dominating, as they need less than a season, while the Arizona Cardinals appear as the weakest team, requiring the most seasons. In contrast, the second redesign for the NFL shows a longer box, indicating a greater disparity between teams. Meanwhile, for the MLS, the box is shorter, reflecting stronger competition and more evenly matched teams. This trend is consistent in the first redesign for MLS, where the number of seasons required by each team is nearly the same.\nThe box plot also helps identify any potential outliers by calculating the upper and lower fences. Values that fall outside these fences are considered outliers. For instance, in the MLS box plot, we observe a value of 1.80 that may be classified as an outlier. However, in this particular case, it might not truly be an outlier. Nonetheless, this feature of box plots is valuable in other scenarios where identifying outliers is crucial..\n\n\n\nIn conclusion, the original visual had a few challenges, making it difficult to identify league-wise performances due to the overcrowding of teams in a single plot, which made trend analysis harder. To address this, we created a line chart grouped by each league, allowing us to easily spot patterns, such as the strongest team and the overall level of competition within the league. We then further refined the design by creating a box plot for each league, providing statistical insights like the distribution of teams, the most common performance range, and the extreme outliers in each league."
  },
  {
    "objectID": "Pages/MidProject.html#original-visual-1",
    "href": "Pages/MidProject.html#original-visual-1",
    "title": "Redesigning plot",
    "section": "2. Original Visual",
    "text": "2. Original Visual\n\nSource: https://www.bloomberg.com/graphics/2021-palm-oil-deforestation-climate-change/\nThe visual above presents data on the global demand for palm oil exports. The graphic illustrates how much palm oil various countries import from Indonesia, as well as the scale of exports, with lines connecting Indonesia to different parts of the world, indicating export volume in monetary terms. [2]\n\nRedesigned Visual 1\nTo enhance clarity regarding the countries that import the largest quantities of palm oil from Indonesia, we have created a horizontal bar graph. This graph is organized in descending order, from the highest to the lowest share of imports. Additionally, the data is categorized by the continent to which each country belongs, allowing for an analysis of which continent is the primary importer of palm oil from Indonesia.\n\n\n\n\n\n\nThe aforementioned chart illustrates that China stands as the foremost importer of palm oil from Indonesia, commanding a market share valued at 2.6 billion dollars. This is succeeded by India, with imports amounting to 2.3 billion dollars, and Pakistan, which imports 1.2 billion dollars. In contrast, the countries with the lowest import figures include South Africa at 172 million dollars, South Korea at 169 million dollars, and Benin at 124 million dollars. Furthermore, it can be deduced that Asia is the predominant continent for palm oil imports, while North America ranks as the continent with the least imports.\n\n\nRedesigned Visual 2\nSame information can be deduced from the below given weighted scatter graph where the dots have size according to their share towards the import of palm oil.\n\n\n\n\n\n\n\n\n\n\n\nRedesigned Visual 3\nThe distribution of palm oil imports has been illustrated on a world map through an interactive format. Nations with the highest levels of imports are represented in darker shades, while those with lower import volumes are shown in lighter shades.\n\n\n\n\n\n\nThe regions exhibiting the highest levels of imports are represented in darker hues, with China leading as the largest importer, indicated by the color red. Following China, India is depicted in orange, while the regions with the lowest imports are shown in lighter shades. Notably, Benin, South Korea, and South Africa are represented by nearly white colors.\n\n\nConclusion\nThe initial visual representation of palm oil imports from Indonesia to various countries was somewhat challenging to interpret due to its cluttered information, making it difficult to identify which nations were the largest importers. However, following its redesign, the information is now presented in a clear and comprehensible manner, allowing for easy identification of the leading importers of palm oil from Indonesia and their respective monetary contributions. Additionally, the redesigned visual facilitates the understanding of the top continents involved in these imports, as illustrated in the maps within redesign plot 3.\n\n\nSpecial Effort\nWe manually created the dataset from the visuals, as it was not readily available in the original article. This extra effort ensured we had data for the analysis and visual redesign.\n\n\nVideo Presentation\n\n\n\nAuthors\n\nAditya Khadse\nAnkit Borle"
  },
  {
    "objectID": "Pages/Code.html#second-visual",
    "href": "Pages/Code.html#second-visual",
    "title": "Code",
    "section": "Second Visual",
    "text": "Second Visual\n\ndata &lt;- read.csv(\"C:/Users/adikh/OneDrive/Desktop/Stat/AnkitBorle/Dataset/stat_proj.csv\")\n\n#Plotting Bar Graph\nbar_graph&lt;-ggplot(data, aes(x = reorder(region, dollars_millions), y = dollars_millions))+\n  geom_bar(stat = 'identity', aes(fill = continent))+\n  coord_flip() +\n  labs(title = \"Share of countries by palm oil import\", y = \"Dollars (in Millions)\", x = \"Region\", fill = \"Continent\") +\n  theme_minimal()\n  \n#Converting Bar Graph to Interactive Graph\nggplotly(bar_graph)\n\n\n\n\n\n\n#Plotting Weighted Scatter Graph\nscatter &lt;- ggplot(data, aes(x = region, y = dollars_millions, size = dollars_millions, color = continent)) +\n  geom_point(alpha = 0.8) +\n  scale_size_continuous(range = c(3, 15)) +\n  geom_text(aes(label = dollars_millions), \n            vjust = 0.5,\n            hjust = 0.5,\n            color = \"black\",\n            size = 2) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 65, hjust = 1)) + \n  labs(title = \"Share of countries by palm oil export\",\n       x = \"Region\",\n       y = \"Dollars (in Millions)\",\n       color = \"Continent\")+\n  guides(size = \"none\")\n\nscatter\n\n\n\n\n\n\n\n\n\nworld_tbl &lt;- map_data(\"world\") %&gt;% as_tibble()\n\nleft &lt;- left_join(world_tbl, data, by=\"region\")\n\nmap1 &lt;- ggplot(left, aes( x = long, y = lat, group=group)) +\n  geom_polygon(aes(fill = dollars_millions), color = \"black\")+\n  scale_fill_gradient2(low = \"white\", mid = \"yellow\", high = \"red\", midpoint = 1500)+\n  labs(title = \"Region wise share of palm oil export\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Million Dollars\")\n\nggplotly(map1)"
  },
  {
    "objectID": "Pages/Code.html",
    "href": "Pages/Code.html",
    "title": "Code",
    "section": "",
    "text": "dataset &lt;- read.csv(\"C:/Users/adikh/OneDrive/Desktop/Stat/AnkitBorle/Dataset/StatDataset.csv\")\n\np1 = ggplot(dataset, aes(x = reorder(Team, -Perfect.Seasons.Needed), y = Perfect.Seasons.Needed, group = League))+\n  geom_point(aes(color = League), size = 2) +\n  geom_line(aes(color = League)) +\n  theme(axis.text.x = element_text(angle = 65, hjust = 1),\n        legend.position = \"right\")   + \n  facet_wrap(~League, scales = \"free_x\", nrow = 3) +\n  labs(x = \"Team\",\n       y = \"Perfect Seasons Needed\")\n\np1\n\n\n\n\n\n\n\n\n\np2 = ggplot(dataset, aes(x = League, y = Perfect.Seasons.Needed, fill = League)) +\n  geom_boxplot() +\n  labs(title = \"Distribution of Perfect Seasons Needed by League\",\n       x = \"League\", y = \"Perfect Seasons Needed\")\n\nggplotly(p2)"
  },
  {
    "objectID": "Pages/Code.html#first-visual",
    "href": "Pages/Code.html#first-visual",
    "title": "Code",
    "section": "",
    "text": "dataset &lt;- read.csv(\"C:/Users/adikh/OneDrive/Desktop/Stat/AnkitBorle/Dataset/StatDataset.csv\")\n\np1 = ggplot(dataset, aes(x = reorder(Team, -Perfect.Seasons.Needed), y = Perfect.Seasons.Needed, group = League))+\n  geom_point(aes(color = League), size = 2) +\n  geom_line(aes(color = League)) +\n  theme(axis.text.x = element_text(angle = 65, hjust = 1),\n        legend.position = \"right\")   + \n  facet_wrap(~League, scales = \"free_x\", nrow = 3) +\n  labs(x = \"Team\",\n       y = \"Perfect Seasons Needed\")\n\np1\n\n\n\n\n\n\n\n\n\np2 = ggplot(dataset, aes(x = League, y = Perfect.Seasons.Needed, fill = League)) +\n  geom_boxplot() +\n  labs(title = \"Distribution of Perfect Seasons Needed by League\",\n       x = \"League\", y = \"Perfect Seasons Needed\")\n\nggplotly(p2)"
  },
  {
    "objectID": "Pages/MidProject.html#conclusion",
    "href": "Pages/MidProject.html#conclusion",
    "title": "Redesigning plot",
    "section": "Conclusion",
    "text": "Conclusion\nIn conclusion, the original visual had a few challenges, making it difficult to identify league-wise performances due to the overcrowding of teams in a single plot, which made trend analysis harder. To address this, we created a line chart grouped by each league, allowing us to easily spot patterns, such as the strongest team and the overall level of competition within the league. We then further refined the design by creating a box plot for each league, providing statistical insights like the distribution of teams, the most common performance range, and the extreme outliers in each league."
  },
  {
    "objectID": "Pages/MidProject.html#references",
    "href": "Pages/MidProject.html#references",
    "title": "Redesigning plot",
    "section": "References",
    "text": "References\n\nPhilip Bump. (2022, December 7). American pro sports franchises, ranked by all-time winning percentage. The Washington Post. https://www.washingtonpost.com/sports/2022/12/07/american-pro-sports-franchise-win-loss-records/\nPablo Robles, Anuradha Raghu, Adam Majendie and Jin Wu. (2021, November 5). The World’s Addiction to Palm Oil is Only Getting Worse. Bloomberg. https://www.bloomberg.com/graphics/2021-palm-oil-deforestation-climate-change/\nWickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T., Miller, E., Bache, S., Müller, K., Ooms, J., Robinson, D., Seidel, D., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686.\nSievert, C. (2020). Interactive web-based data visualization with R, plotly, and shiny. Chapman and Hall/CRC."
  },
  {
    "objectID": "test.html",
    "href": "test.html",
    "title": "Test Author Section",
    "section": "",
    "text": "title: “Test HTML Rendering” format: html\n\n\n\n\nTest Author Section\n\n&lt;div class=\"author\"&gt;\n    &lt;img src=\"author-image.jpg\" alt=\"Author Image\" class=\"author-image\"&gt;\n    &lt;div class=\"author-details\"&gt;\n        &lt;h3 class=\"author-name\"&gt;John Doe&lt;/h3&gt;\n    &lt;/div&gt;\n&lt;/div&gt;"
  },
  {
    "objectID": "Pages/FinalProject.html",
    "href": "Pages/FinalProject.html",
    "title": "Final Project",
    "section": "",
    "text": "by Group 2,"
  },
  {
    "objectID": "Pages/FinalCode.html",
    "href": "Pages/FinalCode.html",
    "title": "Final Code",
    "section": "",
    "text": "Load Dataset and check for empty values\n\n# Load dataset\ndata &lt;- read.csv('C:/Users/adikh/OneDrive/Desktop/Stat/AnkitBorle/Dataset.csv')\nsum(is.na(data))\n\n[1] 0\n\n\n\n\nCheck for duplicate rows\n\n# Check for duplicate rows\nduplicate_rows &lt;- sum(duplicated(data))\nduplicate_rows\n\n[1] 0\n\n\n\n\nTotal number of rows\n\nsum(complete.cases(data))\n\n[1] 1000\n\n\n\n\nColumns in Dataset\n\nlibrary(dplyr)\n# Rename the columns\ndata &lt;- data %&gt;%\n  rename(\n    Patient_Number = No_Pation,\n    Creatinine = Cr,\n    HbA1c_Level = HbA1c,\n    Cholesterol = Chol,\n    Triglycerides = TG,\n    HDL_Cholesterol = HDL,\n    LDL_Cholesterol = LDL,\n    VLDL_Cholesterol = VLDL\n  )\n\ncolnames(data)\n\n [1] \"ID\"               \"Patient_Number\"   \"Gender\"           \"AGE\"             \n [5] \"Urea\"             \"Creatinine\"       \"HbA1c_Level\"      \"Cholesterol\"     \n [9] \"Triglycerides\"    \"HDL_Cholesterol\"  \"LDL_Cholesterol\"  \"VLDL_Cholesterol\"\n[13] \"BMI\"              \"CLASS\"           \n\n\n\n\nRemoving leading and trailing spaces\nBefore removing the spaces\n\ntable(data$CLASS)\n\n\n  N  N    P   Y  Y  \n102   1  53 840   4 \n\n# Apply trimws to all columns in the dataset\ndata &lt;- data.frame(lapply(data, function(x) {\n  if (is.character(x)) {\n    trimws(x) # Trim whitespace for character columns\n  } else {\n    x # Leave other columns unchanged\n  }\n}), stringsAsFactors = FALSE)\n\nAfter removing the spaces\n\ntable(data$CLASS)\n\n\n  N   P   Y \n103  53 844 \n\n\n\n\nCalculate summary statistics (mean, median, standard deviation) for BMI and lipid profiles (LDL, HDL, TG), stratified by CLASS (diabetic vs. non-diabetic).\n\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Assuming `data` is your dataframe loaded into R\n# Group by CLASS and calculate summary statistics\nsummary_stats &lt;- data %&gt;%\n  group_by(CLASS) %&gt;%\n  summarise(\n    BMI_mean = mean(BMI, na.rm = TRUE),\n    BMI_median = median(BMI, na.rm = TRUE),\n    BMI_sd = sd(BMI, na.rm = TRUE),\n    LDL_mean = mean(LDL_Cholesterol, na.rm = TRUE),\n    LDL_median = median(LDL_Cholesterol, na.rm = TRUE),\n    LDL_sd = sd(LDL_Cholesterol, na.rm = TRUE),\n    HDL_mean = mean(HDL_Cholesterol, na.rm = TRUE),\n    HDL_median = median(HDL_Cholesterol, na.rm = TRUE),\n    HDL_sd = sd(HDL_Cholesterol, na.rm = TRUE),\n    TG_mean = mean(Triglycerides, na.rm = TRUE),\n    TG_median = median(Triglycerides, na.rm = TRUE),\n    TG_sd = sd(Triglycerides, na.rm = TRUE)\n  )\n\n# View the results\nsummary_stats %&gt;%\n  kable(format = \"html\", digits = 2) %&gt;%\n  kable_styling(font_size = 10)  # Adjust the font size as needed\n\n\n\n\nCLASS\nBMI_mean\nBMI_median\nBMI_sd\nLDL_mean\nLDL_median\nLDL_sd\nHDL_mean\nHDL_median\nHDL_sd\nTG_mean\nTG_median\nTG_sd\n\n\n\n\nN\n22.37\n22\n1.42\n2.63\n2.6\n0.98\n1.23\n1.1\n0.51\n1.63\n1.3\n1.03\n\n\nP\n23.93\n24\n2.71\n2.49\n2.5\n0.87\n1.13\n1.0\n0.38\n2.13\n1.8\n1.06\n\n\nY\n30.81\n30\n4.32\n2.62\n2.5\n1.14\n1.21\n1.1\n0.69\n2.45\n2.1\n1.43\n\n\n\n\n\n\n\n\n\nMachine learning models for predicting the class of diabetes (N, P, Y) based on clinical and demographic factors?\n\n\nRandom Forest\n\ndata$CLASS &lt;- as.factor(data$CLASS)\n\nset.seed(42)  # For reproducibility\n# Split data -&gt; 80% as training data and 20% as testing data\ntrain_index &lt;- createDataPartition(data$CLASS, p = 0.8, list = FALSE)\ntrain_data &lt;- data[train_index, ]\ntest_data &lt;- data[-train_index, ]\n\n# Fit a Random Forest model\nrf_model &lt;- randomForest(CLASS ~ ., data = train_data, ntree = 100, importance = TRUE,random_state = 42)\n\n# Make predictions on the test set\npredictions &lt;- predict(rf_model, test_data)\n\n# Evaluate the model\nconf_matrix &lt;- confusionMatrix(predictions, test_data$CLASS)\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   N   P   Y\n         N  20   0   2\n         P   0  10   1\n         Y   0   0 165\n\nOverall Statistics\n                                          \n               Accuracy : 0.9848          \n                 95% CI : (0.9564, 0.9969)\n    No Information Rate : 0.8485          \n    P-Value [Acc &gt; NIR] : 5.887e-11       \n                                          \n                  Kappa : 0.9457          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: N Class: P Class: Y\nSensitivity            1.0000  1.00000   0.9821\nSpecificity            0.9888  0.99468   1.0000\nPos Pred Value         0.9091  0.90909   1.0000\nNeg Pred Value         1.0000  1.00000   0.9091\nPrevalence             0.1010  0.05051   0.8485\nDetection Rate         0.1010  0.05051   0.8333\nDetection Prevalence   0.1111  0.05556   0.8333\nBalanced Accuracy      0.9944  0.99734   0.9911\n\n\n\n# Get variable importance from the fitted model\nvar_importance &lt;- randomForest::importance(rf_model)\n\n# Print variable importance\nprint(var_importance)\n\n                           N          P          Y MeanDecreaseAccuracy\nID                2.90033107  3.0463945  2.2066249            4.0638413\nPatient_Number    3.60284624  3.1698481  6.1876847            6.9406985\nGender            0.62418016  1.4389186  0.9721012            1.7955657\nAGE               5.27502908  8.7274922  7.7950173           10.1960232\nUrea              0.05947339  0.4007783  3.4196877            2.2489929\nCreatinine       -0.12163660  2.6791981  3.4951424            3.4406207\nHbA1c_Level      25.83558650 12.7027524 11.1660087           23.7806336\nCholesterol       6.94634560  1.9284815  9.1095206           10.1463380\nTriglycerides     5.92203587  3.6609051  5.6145585            7.7311601\nHDL_Cholesterol  -1.32925931  1.4204124  1.3977476            0.7926818\nLDL_Cholesterol   0.23744178  2.3292662  3.9620622            4.1589452\nVLDL_Cholesterol  6.35132050  4.7634034  6.2262778            8.3446318\nBMI              21.81047332  8.4210010  9.3543430           17.7783627\n                 MeanDecreaseGini\nID                       7.906663\nPatient_Number          11.867330\nGender                   1.709621\nAGE                     25.278841\nUrea                     5.279241\nCreatinine               5.169382\nHbA1c_Level             68.694199\nCholesterol             13.134244\nTriglycerides            9.375600\nHDL_Cholesterol          4.554059\nLDL_Cholesterol          6.381994\nVLDL_Cholesterol         8.575811\nBMI                     54.714782\n\n# Plot variable importance\nvarImpPlot(rf_model, main = \"Variable Importance\")\n\n\n\n\n\n\n\n\n\n\n\nK-Nearest Neighbour\n\ndata$CLASS &lt;- as.factor(data$CLASS)  # Ensure CLASS is a factor\n\n# Scale numeric features\nnumeric_columns &lt;- c(\"AGE\", \"Urea\", \"Creatinine\", \"HbA1c_Level\", \"Cholesterol\", \"BMI\")\ntrain_scaled &lt;- scale(train_data[, numeric_columns])\ntest_scaled &lt;- scale(test_data[, numeric_columns])\n\n# Cross-validation to find the optimal k\nset.seed(42)\nerror&lt;-rep(NA,20) # Placeholder\n\nfor (i in 1:20) {\n  # Perform KNN\n  knn_pred &lt;- knn(train = train_scaled, test = test_scaled, cl = train_data$CLASS, k = i)\n  \n  # Calculate test error\n  error[i] &lt;- mean(knn_pred != test_data$CLASS)\n}\n\nerror_df &lt;- data.frame(\n  K = 1:20,                   # Number of neighbors\n  Error = error               # Test error rates\n)\n\n# Add Accuracy (1 - Error) to the data frame\nerror_df$Accuracy &lt;- 1 - error_df$Error\n\n# Plot accuracy vs. K using ggplot2\nggplot(error_df, aes(x = K, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point() +\n  ggtitle(\"Accuracy vs K for KNN\") +\n  xlab(\"Number of Neighbors (K)\") +\n  ylab(\"Accuracy\") +\n  theme_minimal()\n\n\n\n\n\n\n\nggplot(error_df, aes(x = K, y = Error)) +\n  geom_line(color = \"blue\") +\n  geom_point() +\n  ggtitle(\"Error vs K for KNN\") +\n  xlab(\"Number of Neighbors (K)\") +\n  ylab(\"Error\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Find the minimum error and corresponding K value\nmin_error &lt;- min(error_df$Error)\noptimal_k &lt;- error_df$K[which.min(error_df$Error)]\n\n# Print the results\nprint(paste(\"Minimum Error:\", round(min_error, 4)))\n\n[1] \"Minimum Error: 0.0404\"\n\nprint(paste(\"Optimal K:\", optimal_k))\n\n[1] \"Optimal K: 1\"\n\n\n\n\n\nDecision Tree\n\n###Decision Tree\n\n# Fit a Decision Tree model\ndt_model &lt;- rpart(CLASS ~ ., data = train_data, method = \"class\")\n\n# Plot the Decision Tree\nfancyRpartPlot(dt_model)\n\n\n\n\n\n\n\n# Make predictions on the test data\npredictions &lt;- predict(dt_model, test_data, type = \"class\")\n\n# Evaluate the model\nconf_matrix &lt;- confusionMatrix(predictions, test_data$CLASS)\nprint(conf_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   N   P   Y\n         N  19   0   2\n         P   0  10   0\n         Y   1   0 166\n\nOverall Statistics\n                                          \n               Accuracy : 0.9848          \n                 95% CI : (0.9564, 0.9969)\n    No Information Rate : 0.8485          \n    P-Value [Acc &gt; NIR] : 5.887e-11       \n                                          \n                  Kappa : 0.9441          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: N Class: P Class: Y\nSensitivity           0.95000  1.00000   0.9881\nSpecificity           0.98876  1.00000   0.9667\nPos Pred Value        0.90476  1.00000   0.9940\nNeg Pred Value        0.99435  1.00000   0.9355\nPrevalence            0.10101  0.05051   0.8485\nDetection Rate        0.09596  0.05051   0.8384\nDetection Prevalence  0.10606  0.05051   0.8434\nBalanced Accuracy     0.96938  1.00000   0.9774\n\n# Optional: Print overall accuracy\naccuracy &lt;- conf_matrix$overall[\"Accuracy\"]\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\nAccuracy: 0.9848485 \n\n\n\n\nUse of BMI thresholds to classify individuals into non-diabetic, pre-diabetic, and diabetic categories, and the role BMI plays in predicting diabetes progression across these classes\n\n# Density plot to compare BMI distribution\nggplot(data, aes(x = BMI, fill = CLASS)) +\n  geom_density(alpha = 0.5) +\n  scale_x_continuous(breaks=seq(0,48,by=2))+\n  labs(title = \"BMI Density Plot by CLASS\", x = \"BMI\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nGender-specific differences in clinical markers or diabetes class distributions?\n\n# Correlation Heatmaps by Gender with Values in Boxes\n# Subset data by gender\ndata_male &lt;- subset(data, Gender == \"M\")\ndata_female &lt;- subset(data, Gender == \"F\")\n  \n# Calculate correlation matrix\ncorrelation_matrix_male &lt;- cor(data_male[, c(\"HbA1c_Level\", \"BMI\", \"HDL_Cholesterol\", \"LDL_Cholesterol\", \"Triglycerides\", \"AGE\", \"Urea\", \"Creatinine\")], use = \"complete.obs\")\n\ncorrelation_matrix_female &lt;- cor(data_female[, c(\"HbA1c_Level\", \"BMI\", \"HDL_Cholesterol\", \"LDL_Cholesterol\", \"Triglycerides\", \"AGE\", \"Urea\", \"Creatinine\")], use = \"complete.obs\")\n  \n# Plot heatmap with values\ncorrplot(correlation_matrix_male, method = \"color\", \n           col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(200), \n           addCoef.col = \"black\", # Add values to the boxes in black\n           tl.col = \"black\",      # Labels in black\n           tl.cex = 0.8,          # Adjust label size\n           number.cex = 0.7,      # Adjust coefficient size\n           title = paste(\"Correlation Heatmap for Gender: M\"), mar = c(0, 0, 1, 0))\n\n\n\n\n\n\n\ncorrplot(correlation_matrix_female, method = \"color\", \n           col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(200), \n           addCoef.col = \"black\", # Add values to the boxes in black\n           tl.col = \"black\",      # Labels in black\n           tl.cex = 0.8,          # Adjust label size\n           number.cex = 0.7,      # Adjust coefficient size\n           title = paste(\"Correlation Heatmap for Gender: F\"), mar = c(0, 0, 1, 0))\n\n\n\n\n\n\n\n#linear model\nlm_female &lt;- lm(Creatinine~Urea, data_female)\nlm_male &lt;- lm(Creatinine~Urea, data_male)\n\n\n# Scatterplot for males\nplot_male &lt;- ggplot(data_male, aes(x = Urea, y = Creatinine)) +\n  geom_point(color = \"blue\", alpha = 0.7) +\n  geom_abline(intercept = coef(lm_male)[1], slope = coef(lm_male)[2], color = \"black\") +\n  labs(title = \"Scatterplot of Urea vs Creatine (Males)\",\n       x = \"Urea\", y = \"Creatine\") +\n  theme_minimal()\n\n# Scatterplot for females\nplot_female &lt;- ggplot(data_female, aes(x = Urea, y = Creatinine)) +\n  geom_point(color = \"red\", alpha = 0.7) +\n  geom_abline(intercept = coef(lm_female)[1], slope = coef(lm_female)[2], color = \"black\") +\n  labs(title = \"Scatterplot of Urea vs Creatine (Females)\",\n       x = \"Urea\", y = \"Creatine\") +\n  theme_minimal()\n\n# Arrange the plots side by side\ngrid.arrange(plot_male, plot_female, ncol = 2)\n\n\n\n\n\n\n\n##########\n\n#optimize\n\n# Fit a polynomial regression model (degree 2)\npoly_model &lt;- lm(Creatinine ~ poly(Urea, 2), data = data_female)\n\n# Make predictions\ndata_female$Cr_pred &lt;- predict(poly_model, newdata = data_female)\n\n# Evaluate the model: Mean Squared Error and R-squared\nmse_poly &lt;- mean((data_female$Creatinine - data_female$Cr_pred)^2)\nr2_poly &lt;- summary(poly_model)$r.squared\n\n# Visualization\nggplot(data_female, aes(x = Urea, y = Creatinine)) +\n  geom_point(alpha = 0.7, color = \"purple\", label = \"Data Points\") +\n  stat_smooth(method = \"lm\", formula = y ~ poly(x, 2), color = \"blue\", se = FALSE, label = \"Polynomial Regression Curve\") +\n  labs(title = \"Optimized Polynomial Regression: Urea vs. Creatinine (Gender: F)\",\n       x = \"Urea\", y = \"Creatinine\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  geom_line(aes(y = Cr_pred), color = \"blue\")\n\n\n\n\n\n\n\n# Print evaluation metrics\ncat(\"Evaluation metrics\\n\",\n    \"Mean Squared Error (MSE):\", mse_poly, \"\\n\",\n    \"R-squared (R²):\",r2_poly,\"\\n\")\n\nEvaluation metrics\n Mean Squared Error (MSE): 272.8252 \n R-squared (R²): 0.8057451 \n\n# Fitting the polynomial model\npoly_model &lt;- lm(Creatinine ~ poly(Urea, 2), data = data_female)\n\n# Predictions\npredictions &lt;- predict(poly_model, newdata = data_female)\n\n# Residuals\nresiduals &lt;- data_female$Creatinine - predictions\n\n# Metrics\nmae &lt;- mean(abs(residuals))\nmape &lt;- mean(abs(residuals / data_female$Creatinine)) * 100\naccuracy &lt;- 100 - mape\nr_squared &lt;- summary(poly_model)$r.squared\n\n# Output the results\ncat(\"Results for Females\\n\",\n    \"---------------------\\n\",\n    \"Mean Absolute Error (MAE):\", mae, \"\\n\",\n    \"Mean Absolute Percentage Error (MAPE):\", mape, \"%\\n\",\n    \"Model Accuracy:\", accuracy, \"%\\n\",\n    \"R-squared (R²):\", r_squared, \"\\n\")\n\nResults for Females\n ---------------------\n Mean Absolute Error (MAE): 11.85335 \n Mean Absolute Percentage Error (MAPE): 24.38884 %\n Model Accuracy: 75.61116 %\n R-squared (R²): 0.8057451 \n\n# Fitting the polynomial model for males\npoly_model_male &lt;- lm(Creatinine ~ poly(Urea, 2), data = data_male)\n\n# Predictions for males\npredictions_male &lt;- predict(poly_model_male, newdata = data_male)\n\n# Residuals for males\nresiduals_male &lt;- data_male$Creatinine - predictions_male\n\n# Metrics for males\nmae_male &lt;- mean(abs(residuals_male))  # Mean Absolute Error\nmape_male &lt;- mean(abs(residuals_male / data_male$Creatinine)) * 100  # Mean Absolute Percentage Error\naccuracy_male &lt;- 100 - mape_male  # Accuracy\nr_squared_male &lt;- summary(poly_model_male)$r.squared  # R-squared\n\n# Output the results for males\ncat(\"Results for Males\\n\",\n    \"---------------------\\n\",\n    \"Mean Absolute Error (MAE) for Males:\", mae_male, \"\\n\",\n    \"Mean Absolute Percentage Error (MAPE) for Males:\", mape_male, \"%\\n\",\n    \"Model Accuracy for Males:\", accuracy_male, \"%\\n\",\n    \"R-squared (R²) for Males:\", r_squared_male, \"\\n\")\n\nResults for Males\n ---------------------\n Mean Absolute Error (MAE) for Males: 26.18579 \n Mean Absolute Percentage Error (MAPE) for Males: 32.58835 %\n Model Accuracy for Males: 67.41165 %\n R-squared (R²) for Males: 0.3310646"
  },
  {
    "objectID": "Pages/FinalProject.html#diabetes-overview-causes-and-impact",
    "href": "Pages/FinalProject.html#diabetes-overview-causes-and-impact",
    "title": "Final Project",
    "section": "",
    "text": "by Group 2,"
  },
  {
    "objectID": "Pages/FinalProject.html#abstract",
    "href": "Pages/FinalProject.html#abstract",
    "title": "Final Project",
    "section": "ABSTRACT:",
    "text": "ABSTRACT:\nThis study leverages a comprehensive diabetes dataset to predict diabetes classification using key clinical variables. Visualization techniques were employed to explore patterns and correlations within the data, providing valuable insights into factors influencing diabetes outcomes. Regression analysis was used to build predictive models, enabling the identification of significant predictors for diabetes classification. The findings help explain how clinical variables interact in the diagnosis of diabetes and form a basis for data-driven approaches to the improvement of early detection and management of the disease."
  },
  {
    "objectID": "Pages/FinalProject.html#introduction",
    "href": "Pages/FinalProject.html#introduction",
    "title": "Final Project",
    "section": "INTRODUCTION:",
    "text": "INTRODUCTION:\nDiabetes is one of the major health challenges on the whole planet; it involves millions of people, bringing a considerable contribution to morbidity and mortality rates. Characterized by chronic hyperglycemia, diabetes results either from impaired insulin production or its action, leading to serious complications if not effectively managed. Thus, early diagnosis and proper classification of diabetes are crucial for implementing timely interventions and personalized treatment plans.\nWith the ever-increasing availability of healthcare data, the potential to leverage data analytics in improving our understanding of diabetes is growing. This research study uses a rich dataset that includes clinical and demographic variables for the prediction of diabetes classification with insights into the factors that influence disease outcomes. In this study, we use both the technique of visualization and regression analysis to investigate patterns in data that may result in the diagnosis of diabetes and pinpoint major predictors. This research illustrates the potential of data-driven approaches to further diagnostic precision and clinical decision-making in diabetes care."
  },
  {
    "objectID": "Pages/FinalProject.html#dataset",
    "href": "Pages/FinalProject.html#dataset",
    "title": "Final Project",
    "section": "DATASET:",
    "text": "DATASET:\nThe dataset used in this study includes 1,000 entries, with a diverse set of clinical and demographic variables related to diabetes. Each record contains the following attributes: Patient ID, gender, age, urea levels, creatinine ratio (Cr), glycated hemoglobin (HbA1c), cholesterol (Chol), triglycerides (TG), high-density lipoprotein (HDL), low-density lipoprotein (LDL), very-low-density lipoprotein (VLDL), body mass index (BMI), and a diabetes classification (CLASS) indicating whether the patient is diabetic, non-diabetic, or prediabetic. This dataset provides a robust foundation for analyzing the relationships between these variables and diabetes status, offering a resourceful insight into predictive modeling and valuable ideas about diagnostics and management related to diabetes.\n\n\n    ID No_Pation Gender AGE Urea Cr HbA1c Chol  TG HDL LDL VLDL BMI CLASS\n1  502     17975      F  50  4.7 46   4.9  4.2 0.9 2.4 1.4  0.5  24     N\n2  735     34221      M  26  4.5 62   4.9  3.7 1.4 1.1 2.1  0.6  23     N\n3  420     47975      F  50  4.7 46   4.9  4.2 0.9 2.4 1.4  0.5  24     N\n4  680     87656      F  50  4.7 46   4.9  4.2 0.9 2.4 1.4  0.5  24     N\n5  504     34223      M  33  7.1 46   4.9  4.9 1.0 0.8 2.0  0.4  21     N\n6  634     34224      F  45  2.3 24   4.0  2.9 1.0 1.0 1.5  0.4  21     N\n7  721     34225      F  50  2.0 50   4.0  3.6 1.3 0.9 2.1  0.6  24     N\n8  421     34227      M  48  4.7 47   4.0  2.9 0.8 0.9 1.6  0.4  24     N\n9  670     34229      M  43  2.6 67   4.0  3.8 0.9 2.4 3.7  1.0  21     N\n10 759     34230      F  32  3.6 28   4.0  3.8 2.0 2.4 3.8  1.0  24     N\n\n\n\nHere is a list of features (columns) in the dataset, along with their brief descriptions and types:\n\n\n\n\n\n\n\n\nFeature\nType\nDescription\n\n\n\n\nID\nNumeric\nUnique identifier for each record.\n\n\nNo_Pation\nNumeric\nPatient identification number from the medical center.\n\n\nGender\nCategorical\nGender of the patient (e.g., Male or Female).\n\n\nAGE\nNumeric\nAge of the patient in years.\n\n\nUrea\nNumeric\nUrea level in the blood, indicative of kidney function.\n\n\nCr\nNumeric\nCreatinine level in the blood, used to assess kidney health.\n\n\nHbA1c\nNumeric\nGlycated hemoglobin percentage, a key indicator of diabetes.\n\n\nChol\nNumeric\nTotal cholesterol level in the blood.\n\n\nTG\nNumeric\nLevel of triglycerides in the blood, indicating fat metabolism.\n\n\nHDL\nNumeric\n“Good cholesterol,” helps reduce cardiovascular risks.\n\n\nLDL\nNumeric\n“Bad cholesterol,” associated with plaque buildup in arteries.\n\n\nVLDL\nNumeric\nA type of lipoprotein indicating fat transport.\n\n\nBMI\nNumeric\nA measure of body fat based on weight and height.\n\n\nCLASS\nCategorical\nDiabetes classification, indicating if the patient is diabetic, pre-diabetic or non-diabetic."
  },
  {
    "objectID": "Pages/FinalProject.html#why-this-dataset",
    "href": "Pages/FinalProject.html#why-this-dataset",
    "title": "Final Project",
    "section": "WHY THIS DATASET:",
    "text": "WHY THIS DATASET:\nThe selected dataset offers valuable insights into Type 2 Diabetes, the most common variant of the disease. Medical and demographic parameters include the likes of HbA1c and lipid profiles, BMI, kidney function markers (urea and creatinine), age, and gender. Features offer an in-depth exploration not only of the biological issues but also the lifestyle effects that lead to the complications of diabetes.\nHbA1c is a major indicator of long-term blood glucose control and, thus, stands central in understanding the diagnosis and management of diabetes. The lipid profile data on LDL, HDL, and VLDL allow the investigation into risks related to cardiovascular aspects. Moreover, BMI has critical connotations for obesity, being one of the prime contributory factors towards Type 2 Diabetes. In this context, the inclusion of markers about kidney function underlines the dataset’s usefulness in studying diabetes complications, such as nephropathy.\nThis dataset is a view of real-world conditions and demographic variations, thus providing ample opportunities to study how different factors, such as age and gender, influence the risk and outcomes of diabetes. The diverse nature of features makes it very suitable for building predictive models that identify high-risk individuals and trends, thus contributing to early diagnosis and prevention."
  },
  {
    "objectID": "Pages/FinalProject.html#methodology",
    "href": "Pages/FinalProject.html#methodology",
    "title": "Final Project",
    "section": "METHODOLOGY:",
    "text": "METHODOLOGY:\nThe first preprocessing step for the dataset is to import it into the analysis environment and clean the data. This includes checking for missing values to ensure the completeness of the data, identifying duplicates to avoid redundancy and errors in analysis, and renaming columns to more descriptive and standardized names for better clarity and consistency; thus, making the dataset easier to work with and interpret in further steps.\n\nLoad Dataset and check for empty values\n\n\nCode\n# Load dataset\ndata &lt;- read.csv('C:/Users/adikh/OneDrive/Desktop/Stat/AnkitBorle/Dataset.csv')\nsum(is.na(data))\n\n\n[1] 0\n\n\n\n\nCheck for duplicate rows\n\n\nCode\n# Check for duplicate rows\nduplicate_rows &lt;- sum(duplicated(data))\nduplicate_rows\n\n\n[1] 0\n\n\n\n\nTotal number of rows\n\n\nCode\nsum(complete.cases(data))\n\n\n[1] 1000\n\n\n\n\nColumns in Dataset\n\n\nCode\nlibrary(dplyr)\n# Rename the columns\ndata &lt;- data %&gt;%\n  rename(\n    Patient_Number = No_Pation,\n    Creatinine = Cr,\n    HbA1c_Level = HbA1c,\n    Cholesterol = Chol,\n    Triglycerides = TG,\n    HDL_Cholesterol = HDL,\n    LDL_Cholesterol = LDL,\n    VLDL_Cholesterol = VLDL\n  )\n\ncolnames(data)\n\n\n [1] \"ID\"               \"Patient_Number\"   \"Gender\"           \"AGE\"             \n [5] \"Urea\"             \"Creatinine\"       \"HbA1c_Level\"      \"Cholesterol\"     \n [9] \"Triglycerides\"    \"HDL_Cholesterol\"  \"LDL_Cholesterol\"  \"VLDL_Cholesterol\"\n[13] \"BMI\"              \"CLASS\"           \n\n\n\n\nRemoving leading and trailing spaces\nBefore removing the spaces\n\n\nCode\ntable(data$CLASS)\n\n\n\n  N  N    P   Y  Y  \n102   1  53 840   4 \n\n\nCode\n# Apply trimws to all columns in the dataset\ndata &lt;- data.frame(lapply(data, function(x) {\n  if (is.character(x)) {\n    trimws(x) # Trim whitespace for character columns\n  } else {\n    x # Leave other columns unchanged\n  }\n}), stringsAsFactors = FALSE)\n\n\nAfter removing the spaces\n\n\nCode\ntable(data$CLASS)\n\n\n\n  N   P   Y \n103  53 844 \n\n\n\n\nCalculate summary statistics (mean, median, standard deviation) for BMI and lipid profiles (LDL, HDL, TG), stratified by CLASS (diabetic vs. non-diabetic).\n\n\nCode\nlibrary(knitr)\nlibrary(kableExtra)\n\n# Assuming `data` is your dataframe loaded into R\n# Group by CLASS and calculate summary statistics\nsummary_stats &lt;- data %&gt;%\n  group_by(CLASS) %&gt;%\n  summarise(\n    BMI_mean = mean(BMI, na.rm = TRUE),\n    BMI_median = median(BMI, na.rm = TRUE),\n    BMI_sd = sd(BMI, na.rm = TRUE),\n    LDL_mean = mean(LDL_Cholesterol, na.rm = TRUE),\n    LDL_median = median(LDL_Cholesterol, na.rm = TRUE),\n    LDL_sd = sd(LDL_Cholesterol, na.rm = TRUE),\n    HDL_mean = mean(HDL_Cholesterol, na.rm = TRUE),\n    HDL_median = median(HDL_Cholesterol, na.rm = TRUE),\n    HDL_sd = sd(HDL_Cholesterol, na.rm = TRUE),\n    TG_mean = mean(Triglycerides, na.rm = TRUE),\n    TG_median = median(Triglycerides, na.rm = TRUE),\n    TG_sd = sd(Triglycerides, na.rm = TRUE)\n  )\n\n# View the results\nsummary_stats %&gt;%\n  kable(format = \"html\", digits = 2) %&gt;%\n  kable_styling(font_size = 10)  # Adjust the font size as needed\n\n\n\n\n\nCLASS\nBMI_mean\nBMI_median\nBMI_sd\nLDL_mean\nLDL_median\nLDL_sd\nHDL_mean\nHDL_median\nHDL_sd\nTG_mean\nTG_median\nTG_sd\n\n\n\n\nN\n22.37\n22\n1.42\n2.63\n2.6\n0.98\n1.23\n1.1\n0.51\n1.63\n1.3\n1.03\n\n\nP\n23.93\n24\n2.71\n2.49\n2.5\n0.87\n1.13\n1.0\n0.38\n2.13\n1.8\n1.06\n\n\nY\n30.81\n30\n4.32\n2.62\n2.5\n1.14\n1.21\n1.1\n0.69\n2.45\n2.1\n1.43\n\n\n\n\n\n\n\nThe analysis has shown that BMI and triglycerides are strongly associated with diabetes progression, with diabetic individuals showing significantly higher BMI (30.79–34.52) and TG levels (2.46) compared to non-diabetic (BMI: 22.35–24.60, TG: 1.62) and pre-diabetic groups. LDL levels remain consistent across groups (~2.5–2.6), while HDL shows a slight decline in diabetic individuals, indicating that LDL and HDL may not be reliable markers for diabetes classification. Greater variability of BMI and TG among the diabetic group points to heterogeneity within this group. These results support the view that lifestyle modifications for the prevention and management of diabetes should emphasize obesity and triglycerides. Missing data and variation in effect size would be better assessed through a reevaluation of the data, focusing on a causal approach with age- or sex-specific stratification.\n\n\nMachine learning models for predicting the class of diabetes (N, P, Y) based on clinical and demographic factors?\n\n\nRandom Forest\n\n\nCode\ndata$CLASS &lt;- as.factor(data$CLASS)\n\nset.seed(42)  # For reproducibility\n# Split data -&gt; 80% as training data and 20% as testing data\ntrain_index &lt;- createDataPartition(data$CLASS, p = 0.8, list = FALSE)\ntrain_data &lt;- data[train_index, ]\ntest_data &lt;- data[-train_index, ]\n\n# Fit a Random Forest model\nrf_model &lt;- randomForest(CLASS ~ ., data = train_data, ntree = 100, importance = TRUE,random_state = 42)\n\n# Make predictions on the test set\npredictions &lt;- predict(rf_model, test_data)\n\n# Evaluate the model\nconf_matrix &lt;- confusionMatrix(predictions, test_data$CLASS)\nprint(conf_matrix)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   N   P   Y\n         N  20   0   2\n         P   0  10   1\n         Y   0   0 165\n\nOverall Statistics\n                                          \n               Accuracy : 0.9848          \n                 95% CI : (0.9564, 0.9969)\n    No Information Rate : 0.8485          \n    P-Value [Acc &gt; NIR] : 5.887e-11       \n                                          \n                  Kappa : 0.9457          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: N Class: P Class: Y\nSensitivity            1.0000  1.00000   0.9821\nSpecificity            0.9888  0.99468   1.0000\nPos Pred Value         0.9091  0.90909   1.0000\nNeg Pred Value         1.0000  1.00000   0.9091\nPrevalence             0.1010  0.05051   0.8485\nDetection Rate         0.1010  0.05051   0.8333\nDetection Prevalence   0.1111  0.05556   0.8333\nBalanced Accuracy      0.9944  0.99734   0.9911\n\n\n\n\nConfusion Matrix\n\n\n\nPrediction\nN\nP\nY\n\n\n\n\nPredicted: N\n20\n0\n2\n\n\nPredicted: P\n0\n10\n1\n\n\nPredicted: Y\n0\n0\n165\n\n\n\n\nInsights:\nThe classification results show excellent performance in the identification of diabetic subjects (class Y), with 165 true positives, no false positives, and no false negatives. In the pre-diabetic cases, it correctly classified 10 true positives but had 1 false positive, misclassifying a diabetic case as pre-diabetic. In non-diabetic subjects, the model correctly classified 20 true negatives while misclassifying 2 diabetic cases as non-diabetic. These results present excellent accuracy in class Y, with good performance at class P, while minor misclassifications are presented for class N.\n\n\n\nOverall Statistics\nWith an accuracy of 98.48%, most of the test samples were correctly classified by the Random Forest model. The 95% confidence interval of (95.64%, 99.69%) indicates a highly reliable estimate of accuracy. The model significantly outperformed the baseline No Information Rate (NIR) of 84.85%, as shown by the p-value of 5.887e-11, which indicates performance far better than random guessing on the majority class. Besides, the Kappa statistic of 0.9457 shows very good agreement between the predicted and actual values, reflecting the strength and dependability of the model on classification.\n\n\nStatistics by Class\n\nClass “N” (No Diabetes):\nThis model provides perfect sensitivity-1.000-which correctly identifies all “No Diabetes” cases. It also shows very high specificity, 0.9888, which shows it could exclude 98.88% of the non-“No Diabetes” cases correctly. The balanced accuracy of this class is 0.9944, which denotes the strong and reliable performance of this model.\n\n\nClass “P” (Pre-diabetic):\nFor pre-diabetic cases, the model reaches perfection in sensitivity, correctly selecting all the cases, at 1.000 sensitivity, and a specificity of 0.9947 that correctly excludes 99.47% of the “Pre-diabetic” cases. The balanced accuracy of.9973 underlines again the excellent precision of the model for this class.\n\n\nClass “Y” (Diabetic):\nThe model rightly identifies 98.21% of diabetic cases, hence having a sensitivity of 0.9821, while perfectly excluding all nondiabetic ones with a specificity of 1.000. This good performance for diabetic classification is underlined by a balanced accuracy of 0.9911.\n\n\nCode\n# Get variable importance from the fitted model\nvar_importance &lt;- randomForest::importance(rf_model)\n\n# Print variable importance\nprint(var_importance)\n\n\n                           N          P          Y MeanDecreaseAccuracy\nID                2.90033107  3.0463945  2.2066249            4.0638413\nPatient_Number    3.60284624  3.1698481  6.1876847            6.9406985\nGender            0.62418016  1.4389186  0.9721012            1.7955657\nAGE               5.27502908  8.7274922  7.7950173           10.1960232\nUrea              0.05947339  0.4007783  3.4196877            2.2489929\nCreatinine       -0.12163660  2.6791981  3.4951424            3.4406207\nHbA1c_Level      25.83558650 12.7027524 11.1660087           23.7806336\nCholesterol       6.94634560  1.9284815  9.1095206           10.1463380\nTriglycerides     5.92203587  3.6609051  5.6145585            7.7311601\nHDL_Cholesterol  -1.32925931  1.4204124  1.3977476            0.7926818\nLDL_Cholesterol   0.23744178  2.3292662  3.9620622            4.1589452\nVLDL_Cholesterol  6.35132050  4.7634034  6.2262778            8.3446318\nBMI              21.81047332  8.4210010  9.3543430           17.7783627\n                 MeanDecreaseGini\nID                       7.906663\nPatient_Number          11.867330\nGender                   1.709621\nAGE                     25.278841\nUrea                     5.279241\nCreatinine               5.169382\nHbA1c_Level             68.694199\nCholesterol             13.134244\nTriglycerides            9.375600\nHDL_Cholesterol          4.554059\nLDL_Cholesterol          6.381994\nVLDL_Cholesterol         8.575811\nBMI                     54.714782\n\n\nCode\n# Plot variable importance\nvarImpPlot(rf_model, main = \"Variable Importance\")\n\n\n\n\n\n\n\n\n\nThe variable importance plot shown above provides an assessment of how influential each feature is in the prediction of diabetes classification (“No Diabetes,” “Pre-diabetic,” or “Diabetic”) using a Random Forest model. The two metrics shown in the plots are Mean Decrease in Accuracy and Mean Decrease in Gini.\n\n\n\n1. Mean Decrease in Accuracy\nPermutation importance highlights that HbA1c_Level is the most important variable for this model, which highly reduces the model’s accuracy and finds its basis in the diagnosis of diabetes. The other most important variables are BMI and AGE, pointing to their relevance in predicting diabetes. Cholesterol and VLDL_Cholesterol features are moderately important to classify the instances, whereas HDL_Cholesterol, Gender, and Creatinine do not impact the model’s accuracy so much.\n\n\n2. Mean Decrease in Gini\nFrom the Gini importance in the Random Forest model, the importance plot shows that HbA1c_Level was the most influential variable for it decreases impurity considerably. Following closely were BMI, AGE, and Cholesterol; therefore, all of these confirmed being relevant predictors. For variables such as HDL_Cholesterol, Gender, and Creatinine, their values showed the least importance, showing the very little effect it makes while distinguishing classes.\n\n\nInterpretation of Key Features:\nHbA1c_Level is the most important variable, which directly reflects the long-term blood sugar level and is also one of the major diagnostic criteria for diabetes. BMI is strongly related to Type 2 diabetes risk because it indicates body fat, while AGE points out the vulnerability of older people to this disease. Cholesterol and Triglycerides are moderate predictors, connecting lipid metabolism with diabetes and metabolic disorders. In contrast, variables like HDL_Cholesterol, Gender, and Urea contribute minimally to reducing model uncertainty, offering limited predictive value.\n\n\nPractical Implications:\nThe results emphasize that HbA1c, BMI, and age are the most critical clinical indicators to prioritize in predictive models for diabetes. Lower-importance variables, such as Gender, probably do not add much value in terms of predictive power and could be excluded to gain computational efficiency. These findings can guide healthcare professionals to focus on the most impactful markers for accurate diagnosis and effective treatment strategies.\n\n\n\nK-Nearest Neighbour\n\n\nCode\ndata$CLASS &lt;- as.factor(data$CLASS)  # Ensure CLASS is a factor\n\n# Scale numeric features\nnumeric_columns &lt;- c(\"AGE\", \"Urea\", \"Creatinine\", \"HbA1c_Level\", \"Cholesterol\", \"BMI\")\ntrain_scaled &lt;- scale(train_data[, numeric_columns])\ntest_scaled &lt;- scale(test_data[, numeric_columns])\n\n# Cross-validation to find the optimal k\nset.seed(42)\nerror&lt;-rep(NA,20) # Placeholder\n\nfor (i in 1:20) {\n  # Perform KNN\n  knn_pred &lt;- knn(train = train_scaled, test = test_scaled, cl = train_data$CLASS, k = i)\n  \n  # Calculate test error\n  error[i] &lt;- mean(knn_pred != test_data$CLASS)\n}\n\nerror_df &lt;- data.frame(\n  K = 1:20,                   # Number of neighbors\n  Error = error               # Test error rates\n)\n\n# Add Accuracy (1 - Error) to the data frame\nerror_df$Accuracy &lt;- 1 - error_df$Error\n\n# Plot accuracy vs. K using ggplot2\nggplot(error_df, aes(x = K, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point() +\n  ggtitle(\"Accuracy vs K for KNN\") +\n  xlab(\"Number of Neighbors (K)\") +\n  ylab(\"Accuracy\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\nggplot(error_df, aes(x = K, y = Error)) +\n  geom_line(color = \"blue\") +\n  geom_point() +\n  ggtitle(\"Error vs K for KNN\") +\n  xlab(\"Number of Neighbors (K)\") +\n  ylab(\"Error\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCode\n# Find the minimum error and corresponding K value\nmin_error &lt;- min(error_df$Error)\noptimal_k &lt;- error_df$K[which.min(error_df$Error)]\n\n# Print the results\nprint(paste(\"Minimum Error:\", round(min_error, 4)))\n\n\n[1] \"Minimum Error: 0.0404\"\n\n\nCode\nprint(paste(\"Optimal K:\", optimal_k))\n\n\n[1] \"Optimal K: 1\"\n\n\nThe plots illustrate the relationship between the number of neighbors (K) in a K-Nearest Neighbors (KNN) model and its performance, measured through accuracy and test error. These are derived from cross-validation experiments, where different values of K are evaluated to determine the optimal number of neighbors. Let’s analyze these plots in detail.\n\n\nAccuracy vs. K\nThe plot shows how the model’s accuracy changes when K increases in the KNN algorithm. The highest level of accuracy, ~96%, is captured for K=1, where, however, the model perfectly fits all the training data and thus could overfit, since for each prediction, it relies entirely on the nearest neighbor - therefore, sensitive to noises or outliers. As K increases, accuracy decreases slightly and stabilizes around 92–93% for larger values, reflecting more stable predictions that average over multiple neighbors but may miss finer details in the data. This emphasizes the need for an optimal K to balance accuracy and generalization.\n\n\nError vs. K\nThis graph shows how the error rate changes as K increases in the KNN algorithm, similar to the test error plot. The error is lowest at K=1, capturing local patterns and leading to strong initial performance, but the risk of overfitting remains high. As K increases, the error rises and stabilizes around K=10, with a slight increase at higher values as the model generalizes more and loses its ability to capture finer local structures. This highlights the trade-off between overfitting and underfitting as K is adjusted.\n\nAs we can see that k = 1 gives us the minimum error rate and maximum accuracy but is k = 1 a good option to choose?\nChoosing K=1 is generally not a good idea, even though it yields the highest accuracy in this case. Here’s why:\nWith the KNN algorithm, using a very small value of K-for example, K=1-the model overfits the data since it depends entirely on the nearest neighbor. The resulting model becomes extremely sensitive to noise and outliers, thus yielding unstable predictions and poor generalization performance, though doing well on the test set. Small values of K also introduce a bias-variance trade-off; for instance, K=1 has a low bias but very high variance. Slightly larger values of K, such as 5 or 7, bring in a better balance between bias and variance, hence more stable predictions that generalize well.\n\n\nWhat Value of K is Better?\nFrom the plots, it can be seen that a value of K within the range of 3 to 5 provides an even more stable balance between accuracy and error, minimizing overfitting while maintaining good generalization. While in some instances K=1 may have the lowest test error, it is highly sensitive to noise and therefore fragile. Taking a slightly larger value, such as K=3, gives enhanced model stability and reliability for practical applications that demand consistent results.\n\n\n\n\nDecision Tree\n\n\nCode\n###Decision Tree\n# Fit a Decision Tree model\ndt_model &lt;- rpart(CLASS ~ ., data = train_data, method = \"class\")\n\n# Plot the Decision Tree\nfancyRpartPlot(dt_model)\n\n\n\n\n\n\n\n\n\nCode\n# Make predictions on the test data\npredictions &lt;- predict(dt_model, test_data, type = \"class\")\n\n# Evaluate the model\nconf_matrix &lt;- confusionMatrix(predictions, test_data$CLASS)\nprint(conf_matrix)\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   N   P   Y\n         N  19   0   2\n         P   0  10   0\n         Y   1   0 166\n\nOverall Statistics\n                                          \n               Accuracy : 0.9848          \n                 95% CI : (0.9564, 0.9969)\n    No Information Rate : 0.8485          \n    P-Value [Acc &gt; NIR] : 5.887e-11       \n                                          \n                  Kappa : 0.9441          \n                                          \n Mcnemar's Test P-Value : NA              \n\nStatistics by Class:\n\n                     Class: N Class: P Class: Y\nSensitivity           0.95000  1.00000   0.9881\nSpecificity           0.98876  1.00000   0.9667\nPos Pred Value        0.90476  1.00000   0.9940\nNeg Pred Value        0.99435  1.00000   0.9355\nPrevalence            0.10101  0.05051   0.8485\nDetection Rate        0.09596  0.05051   0.8384\nDetection Prevalence  0.10606  0.05051   0.8434\nBalanced Accuracy     0.96938  1.00000   0.9774\n\n\nCode\n# Optional: Print overall accuracy\naccuracy &lt;- conf_matrix$overall[\"Accuracy\"]\ncat(\"Accuracy:\", accuracy, \"\\n\")\n\n\nAccuracy: 0.9848485 \n\n\nThe decision tree shown above is for diabetes classification, with the structure indicating how decisions are made based on the values of features like BMI, HbA1c, Cholesterol (Chol), and VLDL Cholesterol.\n\n\nTree Structure Explanation\nThe decision tree is rooted on BMI, which splits at 25.5 into the low and high categories of BMI. In the case of &lt; 25.5, further decisions on HbA1c were made and further split by Cholesterol and VLDL Cholesterol, which led to a majority of outcomes being predicted as No Diabetes (N). The most important decision point for the BMI ≥ 25.5 group is HbA1c; the values below 6.4 predict No Diabetes, and values above 6.45 predict Diabetes, which falls into the majority class of this category.\n\n\nKey Insights\nThis feature gives BMI the most important feature ranking, very strongly associated with the disease, followed by HbA1c, one of the major clinical markers for this disease. Other features include Cholesterol and VLDL that provide fine-grained predictions for low BMI and HbA1c, helpful in borderline cases. The majority class prediction at each leaf is decided, either No Diabetes (N) or Diabetes (Y), with the total number of samples, n, and the proportion of each class at each node given.\n\n\nAdvantages of Decision Trees\nIt is also very interpretable, so the decision tree will suit very well for understanding diabetes prediction with respect to features like BMI, HbA1c, and cholesterol. Without pre-processing, it can handle mixed data types, does key predictor selection automatically, and can model complex nonlinear relationships associated with diabetes risk. This is while being fast to train on this dataset and handling missing values natively, ensuring that its performance is robust and versatile.\n\n\nDisadvantages of Decision Trees\nDecision trees can be overfitting, unstable, and biased towards continuous features such as BMI in the diabetes dataset. They are not very good at handling class imbalance issues and do not provide smooth predictions, hence limiting generalization from more advanced models. However, BMI remains a crucial predictor for diabetes analysis.\n\n\nUse of BMI thresholds to classify individuals into non-diabetic, pre-diabetic, and diabetic categories, and the role BMI plays in predicting diabetes progression across these classes\nLets try to understand the distribution of BMI grouped by the Class\n\n\nCode\n# Density plot to compare BMI distribution\nggplot(data, aes(x = BMI, fill = CLASS)) +\n  geom_density(alpha = 0.5) +\n  scale_x_continuous(breaks=seq(0,48,by=2))+\n  labs(title = \"BMI Density Plot by CLASS\", x = \"BMI\", y = \"Density\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\nExplanation of the BMI Density Plot by Class\nThis plot represents the distribution of BMI across classes in diabetic status: “N” for Non-diabetic, “P” for Pre-diabetic, and “Y” for Diabetic. Each class is visualized as a separate density curve to analyze the pattern and overlap in BMI values for each class.\n\n\nKey Insights\nThe plot shows a positive relationship between BMI and diabetes status, where higher values of BMI increase the likelihood of being diabetic, Class Y. The non-diabetic, Class N, has the lowest BMI, the diabetics, Class Y, have the highest, while the pre-diabetics, Class P, are in between. There is an overlap between Classes N and P around a BMI of 20–25 and between Classes P and Y around a BMI of 25–30, which presents challenges in classification. Critical thresholds reflect that a BMI less than 25 is related to non-diabetics, 25-28 to pre-diabetics or diabetics, and above 28 predominantly to diabetics.\n\n\nGender-specific differences in clinical markers or diabetes class distributions\n\n\nCode\n# Correlation Heatmaps by Gender with Values in Boxes\n# Subset data by gender\ndata_male &lt;- subset(data, Gender == \"M\")\ndata_female &lt;- subset(data, Gender == \"F\")\n  \n# Calculate correlation matrix\ncorrelation_matrix_male &lt;- cor(data_male[, c(\"HbA1c_Level\", \"BMI\", \"HDL_Cholesterol\", \"LDL_Cholesterol\", \"Triglycerides\", \"AGE\", \"Urea\", \"Creatinine\")], use = \"complete.obs\")\n\ncorrelation_matrix_female &lt;- cor(data_female[, c(\"HbA1c_Level\", \"BMI\", \"HDL_Cholesterol\", \"LDL_Cholesterol\", \"Triglycerides\", \"AGE\", \"Urea\", \"Creatinine\")], use = \"complete.obs\")\n  \n# Plot heatmap with values\ncorrplot(correlation_matrix_male, method = \"color\", \n           col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(200), \n           addCoef.col = \"black\", # Add values to the boxes in black\n           tl.col = \"black\",      # Labels in black\n           tl.cex = 0.8,          # Adjust label size\n           number.cex = 0.7,      # Adjust coefficient size\n           title = paste(\"Correlation Heatmap for Gender: M\"), mar = c(0, 0, 1, 0))\n\n\n\n\n\n\n\n\n\nCode\ncorrplot(correlation_matrix_female, method = \"color\", \n           col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(200), \n           addCoef.col = \"black\", # Add values to the boxes in black\n           tl.col = \"black\",      # Labels in black\n           tl.cex = 0.8,          # Adjust label size\n           number.cex = 0.7,      # Adjust coefficient size\n           title = paste(\"Correlation Heatmap for Gender: F\"), mar = c(0, 0, 1, 0))\n\n\n\n\n\n\n\n\n\nThe heatmaps for males and females indicate HbA1c, BMI, AGE, Urea, and Creatinine as the important variables in assessing the risk of diabetes. In females, HbA1c is moderately correlated with BMI (0.43) and AGE (0.46), while AGE is moderately correlated with BMI (0.44). Urea and Creatinine are strongly positively correlated with a value of 0.83, showing that they are closely linked as renal markers. In males, the HbA1c is moderately correlated with BMI (0.40) and AGE (0.31), while Urea and Creatinine are also strongly correlated (0.56), though less strong than in females. Other features like HDL, LDL, and TG show a weak correlation in both genders, indicating their minor role in predicting diabetes risk.\n\n\nCode\n#linear model\nlm_female &lt;- lm(Creatinine~Urea, data_female)\nlm_male &lt;- lm(Creatinine~Urea, data_male)\n\n\n# Scatterplot for males\nplot_male &lt;- ggplot(data_male, aes(x = Urea, y = Creatinine)) +\n  geom_point(color = \"blue\", alpha = 0.7) +\n  geom_abline(intercept = coef(lm_male)[1], slope = coef(lm_male)[2], color = \"black\") +\n  labs(title = \"Scatterplot of Urea vs Creatine (Males)\",\n       x = \"Urea\", y = \"Creatine\") +\n  theme_minimal()\n\n# Scatterplot for females\nplot_female &lt;- ggplot(data_female, aes(x = Urea, y = Creatinine)) +\n  geom_point(color = \"red\", alpha = 0.7) +\n  geom_abline(intercept = coef(lm_female)[1], slope = coef(lm_female)[2], color = \"black\") +\n  labs(title = \"Scatterplot of Urea vs Creatine (Females)\",\n       x = \"Urea\", y = \"Creatine\") +\n  theme_minimal()\n\n# Arrange the plots side by side\ngrid.arrange(plot_male, plot_female, ncol = 2)\n\n\n\n\n\n\n\n\n\nThe scatterplots of Urea vs. Creatinine show a strong positive relationship in both males and females, as depicted by the linear trend. In males, values are more spread out, with some outliers at high creatinine levels, suggesting greater variability in renal function. In females, the data points are closer together, with fewer extreme values, indicating more consistent renal marker levels. Overall, the trend reflects that Urea and Creatinine are intimately connected markers of renal health in both genders.\n\n\nOptimizing the plots to better fit model\n\n\nCode\n# Fit a polynomial regression model (degree 2)\npoly_model_f &lt;- lm(Creatinine ~ poly(Urea, 2), data = data_female)\npoly_model_m &lt;- lm(Creatinine ~ poly(Urea, 2), data = data_male)\n\n# Make predictions\ndata_female$Cr_pred &lt;- predict(poly_model_f, newdata = data_female)\ndata_male$Cr_pred &lt;- predict(poly_model_m, newdata = data_male)\n\n# Evaluate the model: Mean Squared Error and R-squared\nmse_poly_f &lt;- mean((data_female$Creatinine - data_female$Cr_pred)^2)\nr2_poly_f &lt;- summary(poly_model_f)$r.squared\n\nmse_poly_m &lt;- mean((data_male$Creatinine - data_male$Cr_pred)^2)\nr2_poly_m &lt;- summary(poly_model_m)$r.squared\n\n# Visualization\n#females\nfemale &lt;- ggplot(data_female, aes(x = Urea, y = Creatinine)) +\n  geom_point(alpha = 0.7, color = \"purple\", label = \"Data Points\") +\n  stat_smooth(method = \"lm\", formula = y ~ poly(x, 2), color = \"blue\", se = FALSE, label = \"Polynomial Regression Curve\") +\n  labs(title = \"Urea vs. Creatinine (Gender: F)\",\n       x = \"Urea\", y = \"Creatinine\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  geom_line(aes(y = Cr_pred), color = \"blue\")\n\n#males\nmale &lt;- ggplot(data_male, aes(x = Urea, y = Creatinine)) +\n  geom_point(alpha = 0.7, color = \"purple\", label = \"Data Points\") +\n  stat_smooth(method = \"lm\", formula = y ~ poly(x, 2), color = \"blue\", se = FALSE, label = \"Polynomial Regression Curve\") +\n  labs(title = \"Urea vs. Creatinine (Gender: M)\",\n       x = \"Urea\", y = \"Creatinine\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  geom_line(aes(y = Cr_pred), color = \"blue\")\n\n# Arrange the plots side by side\ngrid.arrange(\n  male, female,\n  ncol = 2,\n  top = textGrob(\"Urea vs. Creatinine by Gender\", gp = gpar(fontsize = 16, fontface = \"bold\")),\n  heights = c(1, 0.1)\n)\n\n\n\n\n\n\n\n\n\nThe plots illustrate the relationships between Urea and Creatinine for the male and female datasets, respectively, as demonstrated by polynomial regression. For the males, the relationship is wider and has more variability in Creatinine levels, including some extreme outliers above 400. In females, the relationship is more concentrated, showing a steady upward trend with much lower overall variability. In both genders, the strong positive trend in these scatterplots suggests that there would be a close, nonlinear relationship between Urea and Creatinine, signifying their role as key renal markers.\n\n\nCode\n# Print evaluation metrics\ncat(\"Evaluation metrics for females\\n\",\n    \"Mean Squared Error (MSE):\", mse_poly_f, \"\\n\",\n    \"R-squared (R²):\",r2_poly_f,\"\\n\")\n\n\nEvaluation metrics for females\n Mean Squared Error (MSE): 272.8252 \n R-squared (R²): 0.8057451 \n\n\nCode\ncat(\"Evaluation metrics for males\\n\",\n    \"Mean Squared Error (MSE):\", mse_poly_m, \"\\n\",\n    \"R-squared (R²):\",r2_poly_m,\"\\n\")\n\n\nEvaluation metrics for males\n Mean Squared Error (MSE): 3430.41 \n R-squared (R²): 0.3310646 \n\n\nThe evaluation metrics indicate that the model performs significantly better for females compared to males. For females, the low Mean Squared Error (MSE: 272.83) and high R-squared (R²: 0.81) suggest the model explains a substantial portion of the variance in Creatinine based on Urea, with good prediction accuracy. In contrast, for males, the much higher MSE (3430.41) and lower R² (0.33) indicate poor model fit and lower predictive power, likely due to greater variability and the presence of outliers in the male dataset. This highlights a stronger and more reliable relationship between Urea and Creatinine for females.\n\n\nCode\n# Fitting the polynomial model\npoly_model &lt;- lm(Creatinine ~ poly(Urea, 2), data = data_female)\n\n# Predictions\npredictions &lt;- predict(poly_model, newdata = data_female)\n\n# Residuals\nresiduals &lt;- data_female$Creatinine - predictions\n\n# Metrics\nmae &lt;- mean(abs(residuals))\nmape &lt;- mean(abs(residuals / data_female$Creatinine)) * 100\naccuracy &lt;- 100 - mape\nr_squared &lt;- summary(poly_model)$r.squared\n\n# Output the results\ncat(\"Results for Females\\n\",\n    \"---------------------\\n\",\n    \"Mean Absolute Error (MAE):\", mae, \"\\n\",\n    \"Mean Absolute Percentage Error (MAPE):\", mape, \"%\\n\",\n    \"Model Accuracy:\", accuracy, \"%\\n\",\n    \"R-squared (R²):\", r_squared, \"\\n\")\n\n\nResults for Females\n ---------------------\n Mean Absolute Error (MAE): 11.85335 \n Mean Absolute Percentage Error (MAPE): 24.38884 %\n Model Accuracy: 75.61116 %\n R-squared (R²): 0.8057451 \n\n\nCode\n# Fitting the polynomial model for males\npoly_model_male &lt;- lm(Creatinine ~ poly(Urea, 2), data = data_male)\n\n# Predictions for males\npredictions_male &lt;- predict(poly_model_male, newdata = data_male)\n\n# Residuals for males\nresiduals_male &lt;- data_male$Creatinine - predictions_male\n\n# Metrics for males\nmae_male &lt;- mean(abs(residuals_male))  # Mean Absolute Error\nmape_male &lt;- mean(abs(residuals_male / data_male$Creatinine)) * 100  # Mean Absolute Percentage Error\naccuracy_male &lt;- 100 - mape_male  # Accuracy\nr_squared_male &lt;- summary(poly_model_male)$r.squared  # R-squared\n\n# Output the results for males\ncat(\"Results for Males\\n\",\n    \"---------------------\\n\",\n    \"Mean Absolute Error (MAE) for Males:\", mae_male, \"\\n\",\n    \"Mean Absolute Percentage Error (MAPE) for Males:\", mape_male, \"%\\n\",\n    \"Model Accuracy for Males:\", accuracy_male, \"%\\n\",\n    \"R-squared (R²) for Males:\", r_squared_male, \"\\n\")\n\n\nResults for Males\n ---------------------\n Mean Absolute Error (MAE) for Males: 26.18579 \n Mean Absolute Percentage Error (MAPE) for Males: 32.58835 %\n Model Accuracy for Males: 67.41165 %\n R-squared (R²) for Males: 0.3310646 \n\n\nFor females, lower MAE and MAPE are observed at 11.85 and 24.39%, respectively, while higher R-squared and model accuracy of 0.81 and 75.61% support the strong and reliable correlation of Urea with Creatinine. Higher MAE of 26.19 and MAPE of 32.59%, while giving R-squared and model accuracy of 0.33 and 67.41%, respectively, reflect worse model performance in males probably because of more variability with outliers.\n\n\nInference\nFor females, monitoring Urea and Creatinine levels is crucial, as the model effectively predicts their relationship, allowing for early interventions to manage diabetes progression. For males, the model’s performance can be improved by addressing variability and outliers in Urea and Creatinine data and incorporating additional predictors like BMI or HbA1c to better capture metabolic differences and enable more tailored diabetes management strategies.\n\n\n\nAdvantages:\n\nComprehensive Dataset: The inclusion of diverse clinical and demographic variables such as HbA1c, BMI, lipid profiles, and renal markers provides a holistic approach to understanding diabetes.\nEffective Visualizations: Techniques like correlation heatmaps, scatterplots, and density plots facilitate clear insights into relationships between variables.\nStrong Predictive Models: Machine learning algorithms, including Random Forest, Decision Trees, and KNN, demonstrated high accuracy, particularly for diabetic classification.\nGender-Specific Analysis: Stratifying data by gender highlighted key differences in the relationship between Urea and Creatinine, emphasizing the importance of tailored healthcare strategies.\nPractical Implications: Identification of key predictors like HbA1c, BMI, and AGE can guide clinicians in early diagnosis and personalized diabetes management plans.\n\n\n\nDisadvantages:\n\nOutliers and Variability: The male dataset showed significant variability and outliers, reducing the model’s predictive performance.\nClass Imbalance: The dataset has a majority of diabetic cases, which could bias models towards the diabetic class.\nOverfitting in KNN: Using a small value of K, like 1, risks overfitting, making the model sensitive to noise and less generalizable.\nLimited Scope of Analysis: While the focus on BMI and renal markers is valuable, other potential predictors, such as diet and physical activity, are not included in the dataset.\nDependency on Clinical Data: The dataset relies on accurate clinical measurements, which may not always be available in real-world scenarios.\n\n\n\nConclusion\nThe present study illustrates how strong data analytics can support diabetes outcome understanding and predictions with a comprehensive clinical dataset. In fact, the major determinants of diabetes progression were selected on variables like HbA1c, BMI, and AGE. Actionable insight has been provided in various classification and management aspects with visualizations and machine learning models. A very key gender-specific analysis highlights significant differences, particularly for renal markers that underpin the tailored health approaches. Out of all the models used in the study, the decision tree turns out to be highly interpretable and closest to how decisions are taken in medical studies; hence, it can very well be used in various aspects related to diabetes. Limited variability in the male dataset used for experimentation and possible biases are there, but findings indicate an urgent need for data-driven initiatives for better early detection and diagnosis, with personalized management of diabetes.\n\n\nReferences\n[1] A. Kumar, “Diabetes Dataset,” Mendeley Data, V1, Oct. 2018. [Online]. Available: https://data.mendeley.com/datasets/wj9rwkp9c2/1. [Accessed: Dec. 10, 2024].\n[2] National Institute of Diabetes and Digestive and Kidney Diseases, “Diabetes Overview,” NIDDK, 2021. [Online]. Available: https://www.niddk.nih.gov/health-information/diabetes. [Accessed: Dec. 10, 2024]."
  }
]